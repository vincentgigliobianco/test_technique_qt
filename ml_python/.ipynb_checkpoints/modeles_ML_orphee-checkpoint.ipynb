{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osboxes/anaconda3/envs/data/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from functions import *\n",
    "from functions import fun as f\n",
    "import re\n",
    "\n",
    "df_all_data = pd.read_csv(\"data/all_data_before_ml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformation en features numériques adaptées à Scikit-Learn\n",
    "\n",
    "On a besoin de features numériques en vue réaliser une régression logistique de type Ridge et un modèle de type XGBoost<br>\n",
    "pour les variables qui sont toutes catégorielles indiquées ci-dessous suite à la conclusion faite lors de \"1. Statistiques descriptives\"<br>\n",
    "Les variables utilisées sont:\n",
    "- embauche comme variable cible\n",
    "- sexe       \n",
    "- diplome       \n",
    "- specialite \n",
    "- dispo\n",
    "- note_Q     \n",
    "- salaire_Q  \n",
    "- age_D        \n",
    "- note_D       \n",
    "- salaire_D    \n",
    "\n",
    "Bonus: on pourrait créer des nouvelles variables préconisées par les arbres CHAID pour note, salaire et age<br>\n",
    "(on pourrait se contenter de créer \"note_chaid\" en vue de l'utiliser pour xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On renomme specialite, sexe, diplome en specialite_C, sexe_C, diplome_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = df_all_data.rename(columns={'specialite': 'C_specialite', 'sexe': 'C_sexe', 'diplome': 'C_diplome','dispo': 'C_dispo' })\n",
    "# df_all_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle n°1 : régression logistique de type Ridge\n",
    "Je propose de réaliser un premier modèle avec les variables : C_specialite, C_sexe, C_diplome, C_dispo, note, salaire et age\n",
    "- sans interactions\n",
    "- puis avec interactions\n",
    "\n",
    "Ensuite, on pourra voir ce que donne XGBoost<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Création de toutes les variables pour Scikit-Learn\n",
    "- en vue de réaliser une régression logistique (Ridge), les variables catégorielles vont être utilisées\n",
    "sous la forme de \"dummy\" variables (variables indicatrices)\n",
    "- En vue de réaliser une régression XGboost, les variables catégorielles vont être utilisées sous la forme \n",
    "de \"label encodings\" c'est-à-dire que les variables vont être transformées en données numériques grâce à la fonction\n",
    "\"label encoding\" de Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence ici la transformation de toutes les features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme en dummy variables : specialite, sexe, diplome et dispo<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var_name = \"embauche\"\n",
    "all_categorical = [name_var for name_var in list(df_all_data) if name_var[0:1] == 'C'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_sexe', 'C_diplome', 'C_specialite', 'C_dispo']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_data[all_categorical].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cheveux</th>\n",
       "      <th>age</th>\n",
       "      <th>exp</th>\n",
       "      <th>salaire</th>\n",
       "      <th>C_sexe</th>\n",
       "      <th>C_diplome</th>\n",
       "      <th>C_specialite</th>\n",
       "      <th>note</th>\n",
       "      <th>C_dispo</th>\n",
       "      <th>...</th>\n",
       "      <th>annee</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>age_Q</th>\n",
       "      <th>exp_Q</th>\n",
       "      <th>note_Q</th>\n",
       "      <th>salaire_Q</th>\n",
       "      <th>age_D</th>\n",
       "      <th>note_D</th>\n",
       "      <th>salaire_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>blond</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>35554</td>\n",
       "      <td>M</td>\n",
       "      <td>master</td>\n",
       "      <td>geologie</td>\n",
       "      <td>72.41</td>\n",
       "      <td>oui</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[18-30[</td>\n",
       "      <td>[7-9[</td>\n",
       "      <td>[64-76[</td>\n",
       "      <td>[34964-38348[</td>\n",
       "      <td>[18-24[</td>\n",
       "      <td>[71-76[</td>\n",
       "      <td>[34964-36216[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>brun</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>38102</td>\n",
       "      <td>M</td>\n",
       "      <td>licence</td>\n",
       "      <td>geologie</td>\n",
       "      <td>72.46</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[35-42[</td>\n",
       "      <td>[0-7[</td>\n",
       "      <td>[64-76[</td>\n",
       "      <td>[34964-38348[</td>\n",
       "      <td>[40-43[</td>\n",
       "      <td>[71-76[</td>\n",
       "      <td>[37615-39172[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>brun</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>36232</td>\n",
       "      <td>M</td>\n",
       "      <td>licence</td>\n",
       "      <td>geologie</td>\n",
       "      <td>65.43</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[30-35[</td>\n",
       "      <td>[12-23[</td>\n",
       "      <td>[64-76[</td>\n",
       "      <td>[34964-38348[</td>\n",
       "      <td>[31-34[</td>\n",
       "      <td>[61-67[</td>\n",
       "      <td>[36216-37615[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>brun</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>37425</td>\n",
       "      <td>M</td>\n",
       "      <td>master</td>\n",
       "      <td>geologie</td>\n",
       "      <td>92.64</td>\n",
       "      <td>oui</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[30-35[</td>\n",
       "      <td>[0-7[</td>\n",
       "      <td>[87-144[</td>\n",
       "      <td>[34964-38348[</td>\n",
       "      <td>[31-34[</td>\n",
       "      <td>[90-98[</td>\n",
       "      <td>[36216-37615[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>brun</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>46881</td>\n",
       "      <td>M</td>\n",
       "      <td>bac</td>\n",
       "      <td>geologie</td>\n",
       "      <td>29.52</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[18-30[</td>\n",
       "      <td>[12-23[</td>\n",
       "      <td>[9-64[</td>\n",
       "      <td>[38348-53977[</td>\n",
       "      <td>[24-28[</td>\n",
       "      <td>[9-54[</td>\n",
       "      <td>[41358-53977[</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date cheveux  age  exp  salaire C_sexe C_diplome C_specialite   note  \\\n",
       "0  2010-01-01   blond   22    8    35554      M    master     geologie  72.41   \n",
       "1  2010-01-01    brun   42    6    38102      M   licence     geologie  72.46   \n",
       "2  2010-01-01    brun   34   14    36232      M   licence     geologie  65.43   \n",
       "3  2010-01-01    brun   32    7    37425      M    master     geologie  92.64   \n",
       "4  2010-01-01    brun   25   13    46881      M       bac     geologie  29.52   \n",
       "\n",
       "  C_dispo  ...  annee  mois  jour    age_Q    exp_Q    note_Q      salaire_Q  \\\n",
       "0     oui  ...   2010     1     1  [18-30[    [7-9[   [64-76[  [34964-38348[   \n",
       "1     non  ...   2010     1     1  [35-42[    [0-7[   [64-76[  [34964-38348[   \n",
       "2     non  ...   2010     1     1  [30-35[  [12-23[   [64-76[  [34964-38348[   \n",
       "3     oui  ...   2010     1     1  [30-35[    [0-7[  [87-144[  [34964-38348[   \n",
       "4     non  ...   2010     1     1  [18-30[  [12-23[    [9-64[  [38348-53977[   \n",
       "\n",
       "     age_D   note_D      salaire_D  \n",
       "0  [18-24[  [71-76[  [34964-36216[  \n",
       "1  [40-43[  [71-76[  [37615-39172[  \n",
       "2  [31-34[  [61-67[  [36216-37615[  \n",
       "3  [31-34[  [90-98[  [36216-37615[  \n",
       "4  [24-28[   [9-54[  [41358-53977[  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des variables du type interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_sexe', 'C_diplome', 'C_specialite', 'C_dispo']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_interaction = f.interaction_order(df_all_data[all_categorical],all_categorical, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_with_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_categorical = df_all_data[all_categorical].applymap(str)\n",
    "df_with_interaction = df_with_interaction.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_dummies = pd.concat([df_all_categorical,df_with_interaction], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_before_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_dummies = pd.get_dummies(df_before_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = pd.concat([df_all_data,df_all_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dummy_variables = list(df_all_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute maintenant toutes les versions encodées avec \"label encodings\" utiles pour XGBoost<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_before_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in list(df_before_dummies):\n",
    "    f.to_le(df_before_dummies, each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_sexe</th>\n",
       "      <th>C_diplome</th>\n",
       "      <th>C_specialite</th>\n",
       "      <th>C_dispo</th>\n",
       "      <th>C_sexe_+_C_diplome</th>\n",
       "      <th>C_sexe_+_C_specialite</th>\n",
       "      <th>C_sexe_+_C_dispo</th>\n",
       "      <th>C_diplome_+_C_specialite</th>\n",
       "      <th>C_diplome_+_C_dispo</th>\n",
       "      <th>C_specialite_+_C_dispo</th>\n",
       "      <th>C_sexe_labels_encoding</th>\n",
       "      <th>C_diplome_labels_encoding</th>\n",
       "      <th>C_specialite_labels_encoding</th>\n",
       "      <th>C_dispo_labels_encoding</th>\n",
       "      <th>C_sexe_+_C_diplome_labels_encoding</th>\n",
       "      <th>C_sexe_+_C_specialite_labels_encoding</th>\n",
       "      <th>C_sexe_+_C_dispo_labels_encoding</th>\n",
       "      <th>C_diplome_+_C_specialite_labels_encoding</th>\n",
       "      <th>C_diplome_+_C_dispo_labels_encoding</th>\n",
       "      <th>C_specialite_+_C_dispo_labels_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>master</td>\n",
       "      <td>geologie</td>\n",
       "      <td>oui</td>\n",
       "      <td>M_master</td>\n",
       "      <td>M_geologie</td>\n",
       "      <td>M_oui</td>\n",
       "      <td>master_geologie</td>\n",
       "      <td>master_oui</td>\n",
       "      <td>geologie_oui</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>licence</td>\n",
       "      <td>geologie</td>\n",
       "      <td>non</td>\n",
       "      <td>M_licence</td>\n",
       "      <td>M_geologie</td>\n",
       "      <td>M_non</td>\n",
       "      <td>licence_geologie</td>\n",
       "      <td>licence_non</td>\n",
       "      <td>geologie_non</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>licence</td>\n",
       "      <td>geologie</td>\n",
       "      <td>non</td>\n",
       "      <td>M_licence</td>\n",
       "      <td>M_geologie</td>\n",
       "      <td>M_non</td>\n",
       "      <td>licence_geologie</td>\n",
       "      <td>licence_non</td>\n",
       "      <td>geologie_non</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>master</td>\n",
       "      <td>geologie</td>\n",
       "      <td>oui</td>\n",
       "      <td>M_master</td>\n",
       "      <td>M_geologie</td>\n",
       "      <td>M_oui</td>\n",
       "      <td>master_geologie</td>\n",
       "      <td>master_oui</td>\n",
       "      <td>geologie_oui</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>bac</td>\n",
       "      <td>geologie</td>\n",
       "      <td>non</td>\n",
       "      <td>M_bac</td>\n",
       "      <td>M_geologie</td>\n",
       "      <td>M_non</td>\n",
       "      <td>bac_geologie</td>\n",
       "      <td>bac_non</td>\n",
       "      <td>geologie_non</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_sexe C_diplome C_specialite C_dispo C_sexe_+_C_diplome  \\\n",
       "0      M    master     geologie     oui           M_master   \n",
       "1      M   licence     geologie     non          M_licence   \n",
       "2      M   licence     geologie     non          M_licence   \n",
       "3      M    master     geologie     oui           M_master   \n",
       "4      M       bac     geologie     non              M_bac   \n",
       "\n",
       "  C_sexe_+_C_specialite C_sexe_+_C_dispo C_diplome_+_C_specialite  \\\n",
       "0            M_geologie            M_oui          master_geologie   \n",
       "1            M_geologie            M_non         licence_geologie   \n",
       "2            M_geologie            M_non         licence_geologie   \n",
       "3            M_geologie            M_oui          master_geologie   \n",
       "4            M_geologie            M_non             bac_geologie   \n",
       "\n",
       "  C_diplome_+_C_dispo C_specialite_+_C_dispo  C_sexe_labels_encoding  \\\n",
       "0          master_oui           geologie_oui                       1   \n",
       "1         licence_non           geologie_non                       1   \n",
       "2         licence_non           geologie_non                       1   \n",
       "3          master_oui           geologie_oui                       1   \n",
       "4             bac_non           geologie_non                       1   \n",
       "\n",
       "   C_diplome_labels_encoding  C_specialite_labels_encoding  \\\n",
       "0                          3                             3   \n",
       "1                          2                             3   \n",
       "2                          2                             3   \n",
       "3                          3                             3   \n",
       "4                          0                             3   \n",
       "\n",
       "   C_dispo_labels_encoding  C_sexe_+_C_diplome_labels_encoding  \\\n",
       "0                        1                                   7   \n",
       "1                        0                                   6   \n",
       "2                        0                                   6   \n",
       "3                        1                                   7   \n",
       "4                        0                                   4   \n",
       "\n",
       "   C_sexe_+_C_specialite_labels_encoding  C_sexe_+_C_dispo_labels_encoding  \\\n",
       "0                                      7                                 3   \n",
       "1                                      7                                 2   \n",
       "2                                      7                                 2   \n",
       "3                                      7                                 3   \n",
       "4                                      7                                 2   \n",
       "\n",
       "   C_diplome_+_C_specialite_labels_encoding  \\\n",
       "0                                        15   \n",
       "1                                        11   \n",
       "2                                        11   \n",
       "3                                        15   \n",
       "4                                         3   \n",
       "\n",
       "   C_diplome_+_C_dispo_labels_encoding  C_specialite_+_C_dispo_labels_encoding  \n",
       "0                                    7                                       7  \n",
       "1                                    4                                       6  \n",
       "2                                    4                                       6  \n",
       "3                                    7                                       7  \n",
       "4                                    0                                       6  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_before_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_var_label_encodings = [each for each in list(df_before_dummies) if 'encoding' in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste_var_label_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = pd.concat([df_all_data,df_before_dummies[liste_var_label_encodings]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! SPLIT DES DONNEES !!!\n",
    "- données d'apprentissage avec 80% des données \n",
    "- données de test avec 20% des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_all_data[[target_var_name]]\n",
    "X_train_all_columns, X_test_all_columns, Y_train, Y_test = train_test_split(df_all_data,Y_train,test_size = 0.20,random_state = 35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Régression logistique avec régularisation L2\n",
    "### On utilise de la cross validation avec  GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des variables pour la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18320, 95)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sélectionne les variables choisies pour la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------#\n",
    "#------------------ ATTENTION LISTE DES VARIABLES DU MODELE n°1 ---------------------------------------------#\n",
    "#------------------------------------------------------------------------------------------------------------#\n",
    "liste_feat_for_logistic_regression_modele_1 = ['C_sexe_F',\n",
    "'C_sexe_M',\n",
    "'C_diplome_bac',\n",
    "'C_diplome_doctorat',\n",
    "'C_diplome_licence',\n",
    "'C_diplome_master',\n",
    "'C_specialite_archeologie',\n",
    "'C_specialite_detective',\n",
    "'C_specialite_forage',\n",
    "'C_specialite_geologie',\n",
    "'C_dispo_non',\n",
    "'C_dispo_oui',\n",
    "'note',\n",
    "'salaire',\n",
    "'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = []\n",
    "init.append(liste_dummy_variables)\n",
    "numeric_var_to_add = ['note', 'salaire', 'age']\n",
    "init.append(numeric_var_to_add)\n",
    "\n",
    "liste_feat_for_logistic_regression_modele_2 = list(chain(*init))\n",
    "# liste_feat_for_logistic_regression_modele_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! CHOISIR SELECTION MODELE n°1 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_all_columns[liste_feat_for_logistic_regression_modele_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! OU SELECTION MODELE n°2 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_all_columns[liste_feat_for_logistic_regression_modele_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14656, 95)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_all_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrage-réduction des variables numériques utilisées: note, salaire et age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_numeric_to_scale = ['note', 'salaire', 'age']\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame.from_records(scaler.fit_transform(X_train[all_numeric_to_scale]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.columns = all_numeric_to_scale\n",
    "X_train = X_train.drop(all_numeric_to_scale, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification: % d'embauchés proche de 11.4%\n",
    "# len(Y_train[Y_train[\"embauche\"] == 1])/len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = X_train_scaled.index\n",
    "X_train = pd.concat([X_train,X_train_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[all_numeric_to_scale].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 s, sys: 1.28 s, total: 3.64 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='newton-cg',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'C': [0.009, 0.005, 0.001, 0.1, 1, 2, 3, 4, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(solver = \"newton-cg\")\n",
    "parameters = {'C':[0.009, 0.005,0.001, 0.1,1,2,3,4,5,10]}\n",
    "\n",
    "grid_logistic = GridSearchCV(model,parameters, scoring='roc_auc', cv=5, n_jobs = 4, return_train_score = True)\n",
    "grid_logistic.fit(X_train.values, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modèle n°1: sans interactions + numériques standardisées : AUC train = 0.595 , AUC validation = 0.583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.195362</td>\n",
       "      <td>0.232043</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.572653</td>\n",
       "      <td>0.559626</td>\n",
       "      <td>0.581374</td>\n",
       "      <td>0.603972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583462</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.600308</td>\n",
       "      <td>0.594338</td>\n",
       "      <td>0.591163</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.595485</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3       1.195362      0.232043         0.025135        0.016045     0.1   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "3  {'C': 0.1}           0.572653           0.559626           0.581374   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "3           0.603972  ...         0.583462        0.016576                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "3            0.598837            0.600308            0.594338   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "3            0.591163            0.592778          0.595485         0.003517  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_logistic.cv_results_)[pd.DataFrame(grid_logistic.cv_results_)['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle n°2: interactions + variables numériques centrées: AUC train = 0.78, AUC validation = 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.464404</td>\n",
       "      <td>0.428528</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.00626</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>0.771149</td>\n",
       "      <td>0.760693</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.780633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770273</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778286</td>\n",
       "      <td>0.780699</td>\n",
       "      <td>0.775219</td>\n",
       "      <td>0.776489</td>\n",
       "      <td>0.782728</td>\n",
       "      <td>0.778684</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "6       3.464404      0.428528         0.018088         0.00626       3   \n",
       "\n",
       "     params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "6  {'C': 3}           0.771149           0.760693           0.779562   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "6           0.780633  ...         0.770273        0.009011                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "6            0.778286            0.780699            0.775219   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "6            0.776489            0.782728          0.778684         0.002735  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_logistic.cv_results_)[pd.DataFrame(grid_logistic.cv_results_)['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II XGBoost avec Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste variables Modèle n°1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_feat_le_for_xgboost = [each for each in list(df_all_data) if 'labels_encoding' in each and '_+_' not in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = []\n",
    "init.append(liste_feat_le_for_xgboost)\n",
    "numeric_var_to_add = ['note', 'salaire', 'age']\n",
    "init.append(numeric_var_to_add)\n",
    "\n",
    "liste_feat_for_xgboost_modele_1 = list(chain(*init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste_feat_for_xgboost_modele_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste variables Modèle n°2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_feat_le_for_xgboost = [each for each in list(df_all_data) if 'labels_encoding' in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = []\n",
    "init.append(liste_feat_le_for_xgboost)\n",
    "numeric_var_to_add = ['note', 'salaire', 'age']\n",
    "init.append(numeric_var_to_add)\n",
    "\n",
    "liste_feat_for_xgboost_modele_2 = list(chain(*init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! ATTENTION NOUVEAU SPLIT DES DONNEES (80% vers 20%) !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[[target_var_name]]\n",
    "X_train_all_columns, X_valid_all_columns, Y_train, Y_valid = train_test_split(X_train_all_columns,Y_train,test_size = 0.20,random_state = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11724, 95)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! CHOISIR SELECTION MODELE n°1 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_all_columns[liste_feat_for_xgboost_modele_1]\n",
    "X_valid = X_valid_all_columns[liste_feat_for_xgboost_modele_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! OU SELECTION MODELE n°2 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_all_columns[liste_feat_for_xgboost_modele_2]\n",
    "X_valid = X_valid_all_columns[liste_feat_for_xgboost_modele_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11724, 7)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un premier paramétrage du type suivant a été testé:<br>\n",
    "    \n",
    "    subsample_value = np.random.uniform(0.4, 1)\n",
    "    reg_lambda_value = np.random.uniform(1, 5)\n",
    "    reg_alpha_value = np.random.uniform(0.1, 1)\n",
    "    n_estimators_value = np.random.randint(150, 300)\n",
    "    max_depth_value = np.random.randint(7,15)\n",
    "    learning_rate_value = np.random.uniform(0.03, 0.4)\n",
    "    colsample_bytree_value = np.random.uniform(0.7,1)\n",
    "        \n",
    "Après des résultats meilleurs obtenus avec le paramétrage qui suit notamment pour le modèle n°2<br>\n",
    "Je propose donc ci-dessous, les résultats avec ce paramétrage faisant intervenir l'hyperparamètre \"min_child_weight\"<br>\n",
    "et \"reg_lambda\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 27s, sys: 13.1 s, total: 11min 40s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_iter = 100\n",
    "\n",
    "df_result_models = pd.DataFrame(columns = ['colsample_bytree','learning_rate','max_depth','n_estimators','subsample','min_child_weight','reg_lambda','AUC_train','AUC_valid'])\n",
    "\n",
    "for each in range(1,n_iter):\n",
    "    \n",
    "    colsample_bytree_value = np.random.uniform(0.3,0.7)\n",
    "    learning_rate_value = np.random.uniform(0.03, 0.3)\n",
    "    max_depth_value = np.random.randint(7,20)\n",
    "    n_estimators_value = np.random.randint(400, 500)\n",
    "    subsample_value = np.random.uniform(0.4, 0.6)\n",
    "    reg_lambda_value = np.random.uniform(5, 20)\n",
    "    min_child_weight_value = np.random.randint(0,300)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        colsample_bytree = colsample_bytree_value,\n",
    "        learning_rate = learning_rate_value,\n",
    "        max_depth = max_depth_value,\n",
    "        n_estimators = n_estimators_value,\n",
    "        subsample = subsample_value,\n",
    "        reg_lambda = reg_lambda_value,\n",
    "        n_jobs = 4,\n",
    "        min_child_weight = min_child_weight_value,\n",
    "        objective='binary:logistic')\n",
    "        \n",
    "    result = xgb_model.fit(X_train, Y_train.values.ravel())\n",
    "    predicted_values = xgb_model.predict_proba(X_train)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_train_value = roc_auc_score(Y_train.values, predicted_values)\n",
    "    \n",
    "    predicted_values = xgb_model.predict_proba(X_valid)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "        \n",
    "    AUC_valid_value = roc_auc_score(Y_valid.values, predicted_values)\n",
    "    \n",
    "    if AUC_train_value != None and AUC_valid_value != None:\n",
    "    \n",
    "        df_result_models = df_result_models.append({'colsample_bytree': colsample_bytree_value, \n",
    "                                 'learning_rate':learning_rate_value,\n",
    "                                 'max_depth':max_depth_value,\n",
    "                                 'n_estimators':n_estimators_value,\n",
    "                                 'subsample':subsample_value,\n",
    "                                 'reg_lambda':reg_lambda_value,\n",
    "                                 'min_child_weight':min_child_weight_value,                 \n",
    "                                 'AUC_train':AUC_train_value,\n",
    "                                 'AUC_valid':AUC_valid_value}, ignore_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle n°1: avec variables catégorielles sans interactions et variables continues brutes<br>\n",
    "AUC train = 0.91, AUC valid = 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.447386</td>\n",
       "      <td>0.061286</td>\n",
       "      <td>14.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.57636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.016465</td>\n",
       "      <td>0.913873</td>\n",
       "      <td>0.839476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
       "81          0.447386       0.061286       14.0         455.0    0.57636   \n",
       "\n",
       "    min_child_weight  reg_lambda  AUC_train  AUC_valid  \n",
       "81              12.0   11.016465   0.913873   0.839476  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_models[df_result_models['AUC_valid'] == max(df_result_models['AUC_valid'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle n°2 : avec variables catégorielles + interactions et variables continues brutes<br>\n",
    "AUC train = 0.8836, AUC valid = 0.8535<br>\n",
    "Il semble que le modèle n°2 fasse moins de sur-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.460285</td>\n",
       "      <td>0.056231</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.485432</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.080494</td>\n",
       "      <td>0.883656</td>\n",
       "      <td>0.853516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  learning_rate  max_depth  n_estimators  subsample  \\\n",
       "72          0.460285       0.056231        7.0         423.0   0.485432   \n",
       "\n",
       "    min_child_weight  reg_lambda  AUC_train  AUC_valid  \n",
       "72              19.0   16.080494   0.883656   0.853516  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_models[df_result_models['AUC_valid'] == max(df_result_models['AUC_valid'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatisation de \"tuning\" learning rate versus n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai donc obtenu le meilleur modèle avec les hyperparamètres ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_best_model = df_result_models[df_result_models['AUC_valid'] == max(df_result_models['AUC_valid'])]\n",
    "colsample_bytree_value = np.expand_dims(df_result_best_model['colsample_bytree'], axis=1)[0][0]\n",
    "max_depth_value = int(np.expand_dims(df_result_best_model['max_depth'], axis=1)[0][0])\n",
    "subsample_value = np.expand_dims(df_result_best_model['subsample'], axis=1)[0][0]\n",
    "min_child_weight_value = int(np.expand_dims(df_result_best_model['min_child_weight'], axis=1)[0][0])\n",
    "reg_lambda_value = np.expand_dims(df_result_best_model['reg_lambda'], axis=1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une pratique connue : multiplier le learning rate par un facteur et augmenter le nombre d'itérations<br>\n",
    "du modèle (le nombre d'arbres réalisés par XGBoost) par ce même facteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 0.12353585221467042 N_estimators 489\n",
      "0.8368408755975704 -0.08573057902626258\n",
      "Learning rate 0.06176792610733521 N_estimators 978\n",
      "0.8386403256532834 -0.08507337632624856\n",
      "Learning rate 0.04117861740489014 N_estimators 1467\n",
      "0.835568230832824 -0.08935915634069436\n",
      "Learning rate 0.030883963053667605 N_estimators 1956\n",
      "0.83835164983286 -0.08672005693513696\n",
      "Learning rate 0.024707170442934086 N_estimators 2445\n",
      "0.8379562650515798 -0.0872359005675366\n",
      "Learning rate 0.02058930870244507 N_estimators 2934\n",
      "0.8388402645483627 -0.08635598013883161\n",
      "Learning rate 0.01764797888781006 N_estimators 3423\n",
      "0.8377293681032314 -0.08684101036858805\n",
      "Learning rate 0.015441981526833803 N_estimators 3912\n",
      "0.8386077513389166 -0.08619329301802481\n",
      "Learning rate 0.013726205801630047 N_estimators 4401\n",
      "0.8384830703425471 -0.086460416515598\n",
      "CPU times: user 7min 52s, sys: 3.26 s, total: 7min 56s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learning_rate_init = np.expand_dims(df_result_best_model['learning_rate'], axis=1)[0][0]\n",
    "n_estimators_init = int(np.expand_dims(df_result_best_model['n_estimators'], axis=1)[0][0])\n",
    "\n",
    "#learning_rate_init = 0.065352\n",
    "#n_estimators_init = 418\n",
    "\n",
    "factor_trick = range(1,10)\n",
    "\n",
    "for each in factor_trick:\n",
    "    \n",
    "    print (\"Learning rate\",learning_rate_init/each,\"N_estimators\", n_estimators_init*each)\n",
    "    xgb_model = xgb.XGBClassifier( \n",
    "            colsample_bytree = colsample_bytree_value,\n",
    "            learning_rate = learning_rate_init/each,\n",
    "            max_depth = max_depth_value,\n",
    "            n_estimators = n_estimators_init*each,\n",
    "            subsample = subsample_value,\n",
    "            n_jobs = 4,\n",
    "            min_child_weight = min_child_weight_value,\n",
    "            reg_lambda = reg_lambda_value,\n",
    "            objective='binary:logistic')\n",
    "\n",
    "    \n",
    "    xgb_model.fit(X_train, Y_train.values.ravel())\n",
    "    # print (xgb_model.predict_proba(X_train)[:,1])\n",
    "    predicted_values = xgb_model.predict_proba(X_train)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_train_value = roc_auc_score(Y_train.values, predicted_values)\n",
    "\n",
    "    predicted_values = xgb_model.predict_proba(X_valid)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_valid_value = roc_auc_score(Y_valid.values, predicted_values)\n",
    "    \n",
    "    print (AUC_valid_value, AUC_valid_value - AUC_train_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELE n°1:\n",
    "Learning rate 0.12353585221467042 N_estimators 489\n",
    "0.8368408755975704 -0.08573057902626258\n",
    "Learning rate 0.06176792610733521 N_estimators 978\n",
    "0.8386403256532834 -0.08507337632624856\n",
    "Learning rate 0.04117861740489014 N_estimators 1467\n",
    "0.835568230832824 -0.08935915634069436\n",
    "Learning rate 0.030883963053667605 N_estimators 1956\n",
    "0.83835164983286 -0.08672005693513696\n",
    "Learning rate 0.024707170442934086 N_estimators 2445\n",
    "0.8379562650515798 -0.0872359005675366\n",
    "Learning rate 0.02058930870244507 N_estimators 2934\n",
    "0.8388402645483627 -0.08635598013883161\n",
    "Learning rate 0.01764797888781006 N_estimators 3423\n",
    "0.8377293681032314 -0.08684101036858805\n",
    "Learning rate 0.015441981526833803 N_estimators 3912\n",
    "0.8386077513389166 -0.08619329301802481\n",
    "Learning rate 0.013726205801630047 N_estimators 4401\n",
    "0.8384830703425471 -0.086460416515598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELE n° 2:\n",
    "Learning rate 0.05623051444048664 N_estimators 423\n",
    "0.8535155547967361 -0.030140651815787067\n",
    "Learning rate 0.02811525722024332 N_estimators 846\n",
    "0.8543422684303223 -0.030058999820529064\n",
    "Learning rate 0.018743504813495546 N_estimators 1269\n",
    "0.8531403885554077 -0.03128340481474201\n",
    "Learning rate 0.01405762861012166 N_estimators 1692\n",
    "0.8541243574997304 -0.030888915354620128\n",
    "Learning rate 0.01124610288809733 N_estimators 2115\n",
    "0.8532673160562164 -0.03195308682142539\n",
    "Learning rate 0.009371752406747773 N_estimators 2538\n",
    "0.8537671632939146 -0.03138692765399809\n",
    "Learning rate 0.008032930634355234 N_estimators 2961\n",
    "0.8535649778943963 -0.03171570855572636\n",
    "Learning rate 0.00702881430506083 N_estimators 3384\n",
    "0.8537941213471838 -0.031202438157430956\n",
    "Learning rate 0.006247834937831849 N_estimators 3807\n",
    "0.8539839509722872 -0.030938824327446768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stabilité du modèle XGBoost n°2: on lance le meilleur modèle avec trois random states différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851318546121951 0.8534155853491967 -0.03171626926299842\n",
      "0.8851165851803631 0.8520171363358614 -0.03309944884450167\n",
      "0.8854342110212378 0.850760217102189 -0.034673993919048796\n",
      "CPU times: user 24.7 s, sys: 165 ms, total: 24.9 s\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_states = [41,78,168]\n",
    "\n",
    "colsample_bytree_value = 0.460285\n",
    "max_depth_value = 7\n",
    "subsample_value = 0.485432 \n",
    "min_child_weight_value = 19\n",
    "reg_lambda_value = 16.080494\n",
    "\n",
    "learning_rate_value = 0.056231\n",
    "n_estimators_value = 423\n",
    "\n",
    "for rs in random_states:\n",
    "    xgb_model = xgb.XGBClassifier( \n",
    "            colsample_bytree = colsample_bytree_value,\n",
    "            learning_rate = learning_rate_value,\n",
    "            max_depth = max_depth_value,\n",
    "            n_estimators = n_estimators_value,\n",
    "            subsample = subsample_value,\n",
    "            n_jobs = 4,\n",
    "            min_child_weight = min_child_weight_value,\n",
    "            reg_lambda = reg_lambda_value,\n",
    "            objective='binary:logistic',\n",
    "            random_state = rs)\n",
    "\n",
    "    \n",
    "    xgb_model.fit(X_train, Y_train.values.ravel())\n",
    "    predicted_values = xgb_model.predict_proba(X_train)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_train_value = roc_auc_score(Y_train.values, predicted_values)\n",
    "\n",
    "    predicted_values = xgb_model.predict_proba(X_valid)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_valid_value = roc_auc_score(Y_valid.values, predicted_values)\n",
    "    \n",
    "    print (AUC_train_value, AUC_valid_value, AUC_valid_value - AUC_train_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour XGBoost n°1, on utilise les memes random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157885419771842 0.839282825922864 -0.07650571605432022\n",
      "0.9127288077432698 0.840043267675497 -0.07268554006777284\n",
      "0.9136622284721408 0.8409497322166708 -0.07271249625547005\n",
      "CPU times: user 28.9 s, sys: 97.2 ms, total: 29 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_states = [41,78,168]\n",
    "\n",
    "\n",
    "colsample_bytree_value = 0.447386\n",
    "max_depth_value = 14\n",
    "subsample_value = 0.57636 \n",
    "min_child_weight_value = 12\n",
    "reg_lambda_value = 11.016465\n",
    "\n",
    "learning_rate_value = 0.061286\n",
    "n_estimators_value = 455\n",
    "\n",
    "for rs in random_states:\n",
    "    xgb_model = xgb.XGBClassifier( \n",
    "            colsample_bytree = colsample_bytree_value,\n",
    "            learning_rate = learning_rate_value,\n",
    "            max_depth = max_depth_value,\n",
    "            n_estimators = n_estimators_value,\n",
    "            subsample = subsample_value,\n",
    "            n_jobs = 4,\n",
    "            min_child_weight = min_child_weight_value,\n",
    "            reg_lambda = reg_lambda_value,\n",
    "            objective='binary:logistic',\n",
    "            random_state = rs)\n",
    "\n",
    "    \n",
    "    xgb_model.fit(X_train, Y_train.values.ravel())\n",
    "    predicted_values = xgb_model.predict_proba(X_train)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_train_value = roc_auc_score(Y_train.values, predicted_values)\n",
    "\n",
    "    predicted_values = xgb_model.predict_proba(X_valid)[:,1]\n",
    "    predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "    AUC_valid_value = roc_auc_score(Y_valid.values, predicted_values)\n",
    "    \n",
    "    print (AUC_train_value, AUC_valid_value, AUC_valid_value - AUC_train_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion du test des random_states: les deux modèles n°1 et n°2 sont stables<br>\n",
    "en termes de performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori on retient comme meilleur modèle le XGBoost avec interactions<br>\n",
    "Regardons maintenant ce que donne la fonctionnalité \"feature importance\" de Scikit-learn<br>\n",
    "ainsi que la performance du modèle sur le test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on veut sauvegarder les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockage en .pkl\n",
    "# joblib.dump(grid_logistic, \"reg_log_ridge_modele_2.pkl\", compress=9)\n",
    "# joblib.dump(xgb_model, \"reg_log_ridge_modele_2.pkl\", compress=9)\n",
    "# pour le reload\n",
    "# reglog_model = joblib.load(\"reg_log_ridge_modele_2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances que pour XGBoost\n",
    "C'est la décroissance suivant l'impureté d'un noeud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle n°1 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_sexe_labels_encoding',\n",
       " 'C_diplome_labels_encoding',\n",
       " 'C_specialite_labels_encoding',\n",
       " 'C_dispo_labels_encoding',\n",
       " 'note',\n",
       " 'salaire',\n",
       " 'age']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature_importance = {}\n",
    "for each in list(zip(list(X_train),xgb_model.feature_importances_)):\n",
    "    dict_feature_importance[each[0]] = each[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_dispo_labels_encoding  :: 0.25664505\n",
      "C_sexe_labels_encoding  :: 0.16907978\n",
      "C_specialite_labels_encoding  :: 0.16082922\n",
      "C_diplome_labels_encoding  :: 0.1317353\n",
      "note  :: 0.11420831\n",
      "salaire  :: 0.097790316\n",
      "age  :: 0.06971201\n"
     ]
    }
   ],
   "source": [
    "sorted_importances = sorted(dict_feature_importance.items() , reverse = True, key=lambda x: x[1])\n",
    "for elem in sorted_importances :\n",
    "    print(elem[0] , \" ::\" , elem[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle n°2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_sexe_labels_encoding',\n",
       " 'C_diplome_labels_encoding',\n",
       " 'C_specialite_labels_encoding',\n",
       " 'C_dispo_labels_encoding',\n",
       " 'C_sexe_+_C_diplome_labels_encoding',\n",
       " 'C_sexe_+_C_specialite_labels_encoding',\n",
       " 'C_sexe_+_C_dispo_labels_encoding',\n",
       " 'C_diplome_+_C_specialite_labels_encoding',\n",
       " 'C_diplome_+_C_dispo_labels_encoding',\n",
       " 'C_specialite_+_C_dispo_labels_encoding',\n",
       " 'note',\n",
       " 'salaire',\n",
       " 'age']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03213315, 0.04660275, 0.05709283, 0.05794229, 0.06018776,\n",
       "       0.06120392, 0.06787067, 0.0737716 , 0.08094995, 0.08274093,\n",
       "       0.08817929, 0.09438447, 0.19694044], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(xgb_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature_importance = {}\n",
    "for each in list(zip(list(X_train),xgb_model.feature_importances_)):\n",
    "    dict_feature_importance[each[0]] = each[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_specialite_+_C_dispo_labels_encoding  :: 0.19694044\n",
      "C_sexe_labels_encoding  :: 0.09438447\n",
      "C_diplome_+_C_specialite_labels_encoding  :: 0.08817929\n",
      "note  :: 0.082740925\n",
      "C_sexe_+_C_diplome_labels_encoding  :: 0.080949955\n",
      "C_dispo_labels_encoding  :: 0.073771596\n",
      "C_sexe_+_C_dispo_labels_encoding  :: 0.06787067\n",
      "C_sexe_+_C_specialite_labels_encoding  :: 0.061203923\n",
      "C_diplome_+_C_dispo_labels_encoding  :: 0.060187757\n",
      "salaire  :: 0.05794229\n",
      "C_diplome_labels_encoding  :: 0.057092834\n",
      "C_specialite_labels_encoding  :: 0.04660275\n",
      "age  :: 0.032133155\n"
     ]
    }
   ],
   "source": [
    "sorted_importances = sorted(dict_feature_importance.items() , reverse = True, key=lambda x: x[1])\n",
    "for elem in sorted_importances :\n",
    "    print(elem[0] , \" ::\" , elem[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction du modèle n°2 : Regression logistique Ridge sur le test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_sexe_F</th>\n",
       "      <th>C_sexe_M</th>\n",
       "      <th>C_diplome_bac</th>\n",
       "      <th>C_diplome_doctorat</th>\n",
       "      <th>C_diplome_licence</th>\n",
       "      <th>C_diplome_master</th>\n",
       "      <th>C_specialite_archeologie</th>\n",
       "      <th>C_specialite_detective</th>\n",
       "      <th>C_specialite_forage</th>\n",
       "      <th>C_specialite_geologie</th>\n",
       "      <th>...</th>\n",
       "      <th>C_diplome_+_C_dispo_master_non</th>\n",
       "      <th>C_diplome_+_C_dispo_master_oui</th>\n",
       "      <th>C_specialite_+_C_dispo_archeologie_non</th>\n",
       "      <th>C_specialite_+_C_dispo_archeologie_oui</th>\n",
       "      <th>C_specialite_+_C_dispo_detective_non</th>\n",
       "      <th>C_specialite_+_C_dispo_detective_oui</th>\n",
       "      <th>C_specialite_+_C_dispo_forage_non</th>\n",
       "      <th>C_specialite_+_C_dispo_forage_oui</th>\n",
       "      <th>C_specialite_+_C_dispo_geologie_non</th>\n",
       "      <th>C_specialite_+_C_dispo_geologie_oui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11503</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C_sexe_F  C_sexe_M  C_diplome_bac  C_diplome_doctorat  \\\n",
       "4807          1         0              0                   0   \n",
       "11503         1         0              0                   0   \n",
       "2783          1         0              0                   0   \n",
       "767           0         1              0                   1   \n",
       "5949          0         1              0                   0   \n",
       "\n",
       "       C_diplome_licence  C_diplome_master  C_specialite_archeologie  \\\n",
       "4807                   1                 0                         0   \n",
       "11503                  1                 0                         0   \n",
       "2783                   0                 1                         0   \n",
       "767                    0                 0                         0   \n",
       "5949                   1                 0                         0   \n",
       "\n",
       "       C_specialite_detective  C_specialite_forage  C_specialite_geologie  \\\n",
       "4807                        1                    0                      0   \n",
       "11503                       1                    0                      0   \n",
       "2783                        0                    0                      1   \n",
       "767                         0                    0                      1   \n",
       "5949                        0                    1                      0   \n",
       "\n",
       "       ...  C_diplome_+_C_dispo_master_non  C_diplome_+_C_dispo_master_oui  \\\n",
       "4807   ...                               0                               0   \n",
       "11503  ...                               0                               0   \n",
       "2783   ...                               1                               0   \n",
       "767    ...                               0                               0   \n",
       "5949   ...                               0                               0   \n",
       "\n",
       "       C_specialite_+_C_dispo_archeologie_non  \\\n",
       "4807                                        0   \n",
       "11503                                       0   \n",
       "2783                                        0   \n",
       "767                                         0   \n",
       "5949                                        0   \n",
       "\n",
       "       C_specialite_+_C_dispo_archeologie_oui  \\\n",
       "4807                                        0   \n",
       "11503                                       0   \n",
       "2783                                        0   \n",
       "767                                         0   \n",
       "5949                                        0   \n",
       "\n",
       "       C_specialite_+_C_dispo_detective_non  \\\n",
       "4807                                      1   \n",
       "11503                                     0   \n",
       "2783                                      0   \n",
       "767                                       0   \n",
       "5949                                      0   \n",
       "\n",
       "       C_specialite_+_C_dispo_detective_oui  \\\n",
       "4807                                      0   \n",
       "11503                                     1   \n",
       "2783                                      0   \n",
       "767                                       0   \n",
       "5949                                      0   \n",
       "\n",
       "       C_specialite_+_C_dispo_forage_non  C_specialite_+_C_dispo_forage_oui  \\\n",
       "4807                                   0                                  0   \n",
       "11503                                  0                                  0   \n",
       "2783                                   0                                  0   \n",
       "767                                    0                                  0   \n",
       "5949                                   1                                  0   \n",
       "\n",
       "       C_specialite_+_C_dispo_geologie_non  \\\n",
       "4807                                     0   \n",
       "11503                                    0   \n",
       "2783                                     1   \n",
       "767                                      0   \n",
       "5949                                     0   \n",
       "\n",
       "       C_specialite_+_C_dispo_geologie_oui  \n",
       "4807                                     0  \n",
       "11503                                    0  \n",
       "2783                                     0  \n",
       "767                                      1  \n",
       "5949                                     0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_numeric_to_scale = ['note', 'salaire', 'age']\n",
    "scaler = StandardScaler()\n",
    "df_temp = X_test_all_columns[liste_feat_for_logistic_regression_modele_2]\n",
    "X_test_scaled = pd.DataFrame.from_records(scaler.fit_transform(df_temp[all_numeric_to_scale]))\n",
    "X_test_scaled.columns = all_numeric_to_scale\n",
    "df_temp = df_temp.drop(all_numeric_to_scale, axis=1)\n",
    "df_temp.index = X_test_scaled.index\n",
    "df_temp = pd.concat([df_temp,X_test_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77971091778056"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted_values = grid_logistic.predict(X_test_all_columns[liste_feat_for_logistic_regression_modele_2])\n",
    "predicted_values = grid_logistic.predict_proba(df_temp)[:,1]\n",
    "predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "AUC_test_value = roc_auc_score(Y_test.values, predicted_values)\n",
    "AUC_test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'AUC vaut 0.78 sur le test set, pour la régression logistique Ridge<br>\n",
    "sachant que les AUC sur le train set et sur le validation set étaient respectivement de 0.78 et 0.77 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction sur test set XGBoost modèle n°1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = X_test_all_columns[liste_feat_for_xgboost_modele_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8299312634667076"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = xgb_model.predict_proba(df_temp)[:,1]\n",
    "predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "AUC_test_value = roc_auc_score(Y_test.values, predicted_values)\n",
    "AUC_test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction sur test set XGBoost modèle n°2 sans le trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = X_test_all_columns[liste_feat_for_xgboost_modele_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445589101658421"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = xgb_model.predict_proba(df_temp)[:,1]\n",
    "predicted_values = np.expand_dims(predicted_values, axis=1)\n",
    "AUC_test_value = roc_auc_score(Y_test.values, predicted_values)\n",
    "AUC_test_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data bike sharing",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
